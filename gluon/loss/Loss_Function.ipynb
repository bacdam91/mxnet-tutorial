{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Loss Function",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bacdam91/mxnet-tutorial/blob/master/gluon/loss/Loss_Function.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8jTCCslJF3m",
        "colab_type": "text"
      },
      "source": [
        "# Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BZNrxcnJA0B",
        "colab_type": "code",
        "outputId": "841b0125-54c4-4c51-aa85-9810ba5f5eff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!pip install mxnet"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mxnet in /usr/local/lib/python3.6/dist-packages (1.5.1.post0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (1.17.4)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet) (2.21.0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet) (0.8.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dBq3Aj0JJf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mxnet.gluon import nn, loss as gloss\n",
        "from mxnet import nd, autograd\n",
        "from matplotlib import pyplot as plt\n",
        "import mxnet as mx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgUqz1HiK70f",
        "colab_type": "text"
      },
      "source": [
        "## Loss functions for regression\n",
        "\n",
        "The two common loss functions for regression tasks include:\n",
        "1. $l_1$ loss, and\n",
        "2. $l_2$ loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55yBw8EkM_xF",
        "colab_type": "text"
      },
      "source": [
        "### The $l_1$ loss function\n",
        "\n",
        "The $l_1$ loss function calculates the mean absolute error between $label$ and $pred$.\n",
        "\n",
        "> $L = \\sum_{i}|label_{i} - pred_{i}|$\n",
        "\n",
        "When using the ```L1Loss``` in MXNet, we will need to pass in two parameters, ```pred``` and ```label```, where both parameters have the same size. The output of this loss function is a loss tensor with shape of ```batch_size```, Dimensions other than ```batch_axis``` are averaged out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQPfJbZ4NRzx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l1loss = gloss.L1Loss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmo09gtDURpd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "batch_size = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab66oagWNWWL",
        "colab_type": "code",
        "outputId": "bc1a7d1a-13e9-48b1-db33-48c09158c53c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "preds_array = [[1, 3, 2, 3], \n",
        "               [3, 1, 1, 3],\n",
        "               [2, 3, 1, 2]]\n",
        "\n",
        "labels_array = [[4, 4, 4, 4],\n",
        "                [4, 4, 4, 4],\n",
        "                [4, 4, 4, 4]]\n",
        "\n",
        "preds = nd.array(preds_array)\n",
        "labels = nd.array(labels_array)\n",
        "print(\"Predictions:\", preds)\n",
        "print(\"Labels:\", labels)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predictions: \n",
            "[[1. 3. 2. 3.]\n",
            " [3. 1. 1. 3.]\n",
            " [2. 3. 1. 2.]]\n",
            "<NDArray 3x4 @cpu(0)>\n",
            "Labels: \n",
            "[[4. 4. 4. 4.]\n",
            " [4. 4. 4. 4.]\n",
            " [4. 4. 4. 4.]]\n",
            "<NDArray 3x4 @cpu(0)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nth0SxD8No2z",
        "colab_type": "code",
        "outputId": "00537c1e-4543-47ee-e626-c1042b2766ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "output = l1loss(preds, labels)\n",
        "output"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[1.75 2.   2.  ]\n",
              "<NDArray 3 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_heLWV57cYI3",
        "colab_type": "text"
      },
      "source": [
        "### Manual working out of $l_1$ loss function\n",
        "\n",
        "Let's manually workout the example from above so that we can have a solid understanding of the $l_1$ loss function and how ```mxnet``` process the input and generate the output.\n",
        "\n",
        "Let's first have a look at the first row of the predictions and work out its $l_1$ loss. \n",
        "\n",
        "#### Row #1\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <td><strong>Preds</strong></td>\n",
        "        <td>1</td>\n",
        "        <td>3</td>\n",
        "        <td>2</td>\n",
        "        <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td><strong>Labels</strong></td>\n",
        "        <td>4</td>\n",
        "        <td>4</td>\n",
        "        <td>4</td>\n",
        "        <td>4</td>\n",
        "        <td><strong>Total</strong></td>\n",
        "        <td><strong>Average</strong></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td><strong>|Preds - Labels|<strong></td>\n",
        "        <td>3</td>\n",
        "        <td>1</td>\n",
        "        <td>2</td>\n",
        "        <td>1</td>\n",
        "        <td>7</td>\n",
        "        <td>1.75</td>\n",
        "    </tr>\n",
        "</table>\n",
        "\n",
        "All of our labels have values of 4. For each column in the table above, we will find the absolute difference between the our predictions and the truth labels. After that, we will find the sum of the absolute difference, which is 7, and divide by 4 (the number of elements per row), which is 1.75 and equals to that produced by the function.\n",
        "\n",
        "We can do the same working out for the remaining two rows.\n",
        "\n",
        "#### Row #2\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <td><strong>Preds</strong></td>\n",
        "        <td>3</td>\n",
        "        <td>1</td>\n",
        "        <td>1</td>\n",
        "        <td>3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td><strong>Labels</strong></td>\n",
        "        <td>4</td>\n",
        "        <td>4</td>\n",
        "        <td>4</td>\n",
        "        <td>4</td>\n",
        "        <td><strong>Total</strong></td>\n",
        "        <td><strong>Average</strong></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td><strong>|Preds - Labels|<strong></td>\n",
        "        <td>1</td>\n",
        "        <td>3</td>\n",
        "        <td>3</td>\n",
        "        <td>1</td>\n",
        "        <td>8</td>\n",
        "        <td>2</td>\n",
        "    </tr>\n",
        "</table>\n",
        "\n",
        "#### Row #3:\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <td><strong>Preds</strong></td>\n",
        "        <td>2</td>\n",
        "        <td>3</td>\n",
        "        <td>1</td>\n",
        "        <td>2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td><strong>Labels</strong></td>\n",
        "        <td>4</td>\n",
        "        <td>4</td>\n",
        "        <td>4</td>\n",
        "        <td>4</td>\n",
        "        <td><strong>Total</strong></td>\n",
        "        <td><strong>Average</strong></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td><strong>|Preds - Labels|<strong></td>\n",
        "        <td>2</td>\n",
        "        <td>1</td>\n",
        "        <td>3</td>\n",
        "        <td>2</td>\n",
        "        <td>8</td>\n",
        "        <td>2</td>\n",
        "    </tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4w2WHkJKSFh",
        "colab_type": "text"
      },
      "source": [
        "### The $l_2$ loss function\n",
        "\n",
        "The $l_2$ loss function calculates the mean squared error between $label$ and $pred$.\n",
        "\n",
        "> $L = \\frac{1}{2}\\sum_{i}|label_{i} - pred_{i}|^{2}$\n",
        "\n",
        "When using the ```L2Loss``` in MXNet, we will need to pass in two parameters, ```pred``` and ```label```, where both parameters have the same size. The output of this loss function is a loss tensor with shape of ```batch_size```, Dimensions other than ```batch_axis``` are averaged out."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSnrMqrNJdcK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l2loss = gloss.L2Loss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obd1wRwYLRSh",
        "colab_type": "code",
        "outputId": "53eb4aa5-12fc-4aee-e493-df7be0ec77d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "output = l2loss(preds, labels)\n",
        "output"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[1.875 2.5   2.25 ]\n",
              "<NDArray 3 @cpu(0)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFII8SNNneLI",
        "colab_type": "text"
      },
      "source": [
        "### Manual working out of $l_2$ loss function\n",
        "\n",
        "Again, let's manually workout the example from above so that we can have a solid understanding of the $l_2$ loss function and how ```mxnet``` process the input and generate the output.\n",
        "\n",
        "Let's first have a look at the first row of the predictions and work out its $l_2$ loss. \n",
        "\n",
        "#### Row #1\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <td><strong>Preds</strong></td>\n",
        "        <td>1</td>\n",
        "        <td>3</td>\n",
        "        <td>2</td>\n",
        "        <td>1</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td><strong>Labels</strong></td>\n",
        "        <td>4</td>\n",
        "        <td>4</td>\n",
        "        <td>4</td>\n",
        "        <td>4</td>\n",
        "        <td><strong>Total</strong></td>\n",
        "        <td><strong>Average</strong></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td><strong>|Preds - Labels|<sup>2</sup><strong></td>\n",
        "        <td>9</td>\n",
        "        <td>1</td>\n",
        "        <td>4</td>\n",
        "        <td>1</td>\n",
        "        <td>15</td>\n",
        "        <td>1.875</td>\n",
        "    </tr>\n",
        "</table>\n",
        "\n",
        "We are using the same ```preds``` and ```labels``` as with $l_1$, so all of our labels have values of 4. For each column in the table above, we will find the square of the absolute difference between the our predictions and the truth labels. After that, we will find the sum of the absolute difference, which is 15, and divide by 2 (as per equation) then divide again by 4 (the number of elements per row), which is 1.875 and equals to that produced by the function.\n",
        "\n",
        "We can do the same working out for the remaining two rows.\n",
        "\n",
        "#### Row #2\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <td><strong>Preds</strong></td>\n",
        "        <td>3</td>\n",
        "        <td>1</td>\n",
        "        <td>1</td>\n",
        "        <td>3</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td><strong>Labels</strong></td>\n",
        "        <td>4</td>\n",
        "        <td>4</td>\n",
        "        <td>4</td>\n",
        "        <td>4</td>\n",
        "        <td><strong>Total</strong></td>\n",
        "        <td><strong>Average</strong></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td><strong>|Preds - Labels|<sup>2</sup><strong></td>\n",
        "        <td>1</td>\n",
        "        <td>9</td>\n",
        "        <td>9</td>\n",
        "        <td>1</td>\n",
        "        <td>10</td>\n",
        "        <td>2.5</td>\n",
        "    </tr>\n",
        "</table>\n",
        "\n",
        "#### Row #3:\n",
        "\n",
        "<table>\n",
        "    <tr>\n",
        "        <td><strong>Preds</strong></td>\n",
        "        <td>2</td>\n",
        "        <td>3</td>\n",
        "        <td>1</td>\n",
        "        <td>2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td><strong>Labels</strong></td>\n",
        "        <td>4</td>\n",
        "        <td>4</td>\n",
        "        <td>4</td>\n",
        "        <td>4</td>\n",
        "        <td><strong>Total</strong></td>\n",
        "        <td><strong>Average</strong></td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "        <td><strong>|Preds - Labels|<sup>2</sup><strong></td>\n",
        "        <td>4</td>\n",
        "        <td>1</td>\n",
        "        <td>9</td>\n",
        "        <td>4</td>\n",
        "        <td>18</td>\n",
        "        <td>2.25</td>\n",
        "    </tr>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALcSvAp2Ye2L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}